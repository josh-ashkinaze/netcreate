{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "from tenacity import RetryCallState\n",
    "import jsonlines\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    "    before_sleep_log\n",
    ")  # for exponential backoff\n",
    "\n",
    "#####################################\n",
    "## GLOBAL CONSTANTS ##\n",
    "with open('../../creds/openai_creds.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "RANDOM_SEED = 416\n",
    "API_KEY = data['api_key']\n",
    "example_df = pd.read_csv(\"../../data/gt_main2.csv\")\n",
    "AUT_ITEMS = [\"box\", \"fork\", \"lightbulb\", \"spoon\", \"table\"]\n",
    "PROMPTS = {\n",
    "    \"zero_shot\": \"What are some creative uses for [OBJECT_NAME]? The goal is to come up with a creative idea, which is an idea that strikes people as clever, unusual, interesting, uncommon, humorous, innovative, or different. List [N] creative uses for [OBJECT_NAME].\",\n",
    "\n",
    "    \"implicit\": \"What are some creative uses for [OBJECT_NAME]? The goal is to come up with a creative idea, which is an idea that strikes people as clever, unusual, interesting, uncommon, humorous, innovative, or different. Here are example creative uses: [EXAMPLES] Based on the examples, list [N] creative uses for [OBJECT_NAME] that sounds like the examples.\",\n",
    "\n",
    "    \"explicit\": \"What are some creative uses for [OBJECT_NAME]? The goal is to come up with a creative idea, which is an idea that strikes people as clever, unusual, interesting, uncommon, humorous, innovative, or different. Here are example creative uses: [EXAMPLES] Carefully study the examples and their style, then list [N] creative uses for [OBJECT_NAME] that resemble the given examples. Match the style, length, and complexity of the creative ideas in the examples.\",\n",
    "}\n",
    "TEMPERATURE = 0.7\n",
    "FREQUENCY_PENALTY = 1.5\n",
    "PRESCENCE_PENALTY = 1\n",
    "\n",
    "# Define originality quartiles\n",
    "FIRST_Q = np.percentile(example_df['target'], 0.25)\n",
    "THIRD_Q = np.percentile(example_df['target'], 0.25)\n",
    "\n",
    "random.seed(416)\n",
    "#####################################\n",
    "\n",
    "\n",
    "def handle_prompt(args):\n",
    "    prompt_base, object_name, examples, n_examples, temperature, frequency_penalty, presence_penalty = args\n",
    "    prompt = make_prompt(prompt_base, object_name, examples, n_examples)\n",
    "    response = generate_responses(prompt, temperature, frequency_penalty, presence_penalty)\n",
    "    return response\n",
    "\n",
    "\n",
    "def make_prompt(prompt_base, object_name, examples, n_examples):\n",
    "    prompt = prompt_base.replace(\"[OBJECT_NAME]\", object_name)\n",
    "    prompt = prompt.replace(\"[N]\", str(n_examples))\n",
    "    examples = \" \".join(['\\n- ' + item for item in examples]) + \"\\n\"\n",
    "    prompt = prompt.replace(\"[EXAMPLES]\", examples)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=30, min=1, max=60), stop=stop_after_attempt(30),before_sleep=before_sleep_log(logging, logging.INFO))\n",
    "def generate_responses(prompt, temperature, frequency_penalty, presence_penalty):\n",
    "    openai.api_key = API_KEY\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=2000,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"text\"]\n",
    "    return message\n",
    "\n",
    "\n",
    "def get_examples(df, prompt, n_examples, seed=416):\n",
    "    return df[df['prompt'] == prompt].sample(n_examples, random_state=seed)['response'].tolist()\n",
    "\n",
    "\n",
    "def split_ideas(x):\n",
    "    x = x.split(\"\\n\")\n",
    "    x = [(l.replace(\"- \", \"\").strip()).lower() for l in x]\n",
    "    x = [l for l in x if l]\n",
    "    return x\n",
    "\n",
    "\n",
    "def remove_number_prefix(response):\n",
    "    return re.sub(r'^\\d+\\.', '', response).strip()\n",
    "\n",
    "\n",
    "def log_before_sleep(retry_state: RetryCallState):\n",
    "    logging.info(f\"Waiting {retry_state.next_action.sleep} seconds before retrying...\")\n",
    "    \n",
    "\n",
    "def make_stimuli_sets(): \n",
    "    sep = \"br\"\n",
    "    stimuli_str_sets = []\n",
    "    stimuli_sets = []\n",
    "    for aut_item in AUT_ITEMS:\n",
    "        logging.info(\"Making stimuli for item\".format(aut_item))\n",
    "        stimuli = {}\n",
    "        stimuli['human'] = get_examples(example_df, aut_item, 8, seed=RANDOM_SEED)\n",
    "        gpt_human_seeds = get_examples(example_df, aut_item, 8, seed=RANDOM_SEED+10)\n",
    "\n",
    "        few_gpt_args =  (PROMPTS['implicit'],\n",
    "                                \"a \" + aut_item,\n",
    "                                gpt_human_seeds,\n",
    "                                2,\n",
    "                                TEMPERATURE,\n",
    "                                FREQUENCY_PENALTY,\n",
    "                                PRESCENCE_PENALTY\n",
    "                        )\n",
    "\n",
    "        many_gpt_args =  (PROMPTS['implicit'],\n",
    "                            \"a \" + aut_item,\n",
    "                            gpt_human_seeds,\n",
    "                            6,\n",
    "                            TEMPERATURE,\n",
    "                            FREQUENCY_PENALTY,\n",
    "                            PRESCENCE_PENALTY\n",
    "                    )\n",
    "\n",
    "        stimuli['few_gpt_unlabled'] = [remove_number_prefix(x) for x in split_ideas(handle_prompt(few_gpt_args))] + [remove_number_prefix(x) for x in random.sample(stimuli['human'], 6)]\n",
    "        stimuli['many_gpt_unlabled'] = [remove_number_prefix(x) for x in split_ideas(handle_prompt(many_gpt_args))] + [remove_number_prefix(x) for x in random.sample(stimuli['human'], 2)]\n",
    "        stimuli['few_gpt_labled'] = [remove_number_prefix(x) + \" (SOURCE: AI)\" for x in stimuli['few_gpt_unlabled'][:2]] + [remove_number_prefix(x) + \" (SOURCE: HUMAN)\" for x in stimuli['few_gpt_unlabled'][2:]]\n",
    "        stimuli['many_gpt_labled'] = [remove_number_prefix(x) + \" (SOURCE: AI)\" for x in stimuli['many_gpt_unlabled'][:6]] + [remove_number_prefix(x) + \" (SOURCE: HUMAN)\" for x in stimuli['many_gpt_unlabled'][6:]]\n",
    "        stimuli['item_name'] = aut_item\n",
    "        stimuli_str = {k: (f\"{sep} \" + f\"\\n{sep} \".join(v)) if k != 'item_name' else v for k, v in stimuli.items()}\n",
    "        stimuli_sets.append(stimuli)\n",
    "        stimuli_str_sets.append(stimuli_str)\n",
    "    stim_df = pd.DataFrame(stimuli_sets)\n",
    "    stim_df.to_csv(\"stimuli_sets.csv\")\n",
    "    \n",
    "    stim_str_df = pd.DataFrame(stimuli_str_sets)\n",
    "    stim_str_df.to_csv(\"stimuli_str_sets.csv\")\n",
    "    return stim_df, stim_str_df\n",
    "\n",
    "def main():\n",
    "    now = datetime.now()\n",
    "    date_string = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    log_file = f\"get_conditions_{date_string}.log\"\n",
    "\n",
    "    logging.info(\"Making stimuli sets\")\n",
    "    stim_df, stim_str_df = make_stimuli_sets()\n",
    "    \n",
    "    \n",
    "    logging.info(\"Making experiment conditions for Qualtrics loop&merge\")\n",
    "\n",
    "    CONDITIONS = [\n",
    "    \"human\",\n",
    "    \"few_gpt_unlabled\",\n",
    "    \"many_gpt_unlabled\",\n",
    "    \"few_gpt_labled\",\n",
    "    \"many_gpt_labled\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    all_orders = list(itertools.permutations(AUT_ITEMS))\n",
    "    conditions_data = []\n",
    "    for item_order in all_orders:\n",
    "        condition_data = {}\n",
    "        condition_data['idx'] = \"_\".join(item_order)\n",
    "        for c in range(len(CONDITIONS)):\n",
    "            cond_str = CONDITIONS[c] # The str of the condition \n",
    "            cond_item = item_order[c] # The str of the item\n",
    "            condition_data[f'{cond_str}_item'] = cond_item\n",
    "            condition_data[f'{cond_str}_set'] = stim_df[stim_df['item_name'] == cond_item][cond_str].tolist()[0]\n",
    "            \n",
    "            # Due to Qualtrics loop and merge, we have to add each answer as its own column\n",
    "            # E.g: human1, human2...\n",
    "            for r in range(len(condition_data[f'{cond_str}_set'])):\n",
    "                condition_data[f'{cond_str}_r{r}'] = condition_data[f'{cond_str}_set'][r]\n",
    "        conditions_data.append(condition_data)\n",
    "\n",
    "    cond_df = pd.DataFrame(conditions_data)\n",
    "    cond_df.to_csv(\"condition_df.csv\")\n",
    "\n",
    "\n",
    "cond_df = main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (misinformation_sim)",
   "language": "python",
   "name": "pycharm-9607488f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
